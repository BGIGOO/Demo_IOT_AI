# =============================================================================
# CHÆ¯Æ NG TRÃŒNH TRAIN AI NHáº¬N DIá»†N GIá»ŒNG NÃ“I (PHIÃŠN Báº¢N ONE-CLICK)
# Há»— trá»£: .wav, .mp3, .m4a
# =============================================================================

# 1. CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t (Cháº¡y siÃªu tá»‘c)
!pip install -q librosa numpy scikit-learn joblib resampy

import librosa
import numpy as np
import os
import glob
import zipfile
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# --- Cáº¤U HÃŒNH ---
DATASET_ZIP = "dataset_giong_noi.zip" # TÃªn file zip báº¡n upload lÃªn
DATA_DIR = "dataset_giong_noi"      # TÃªn thÆ° má»¥c sau khi giáº£i nÃ©n

# --- HÃ€M TRÃCH XUáº¤T Äáº¶C TRÆ¯NG MFCC ---
def extract_features(file_path):
    try:
        # Load file Ã¢m thanh (tá»± Ä‘á»™ng nháº­n diá»‡n mp3, m4a, wav)
        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')

        # TrÃ­ch xuáº¥t MFCC (Láº¥y 40 Ä‘áº·c trÆ°ng quan trá»ng nháº¥t)
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)

        # Láº¥y trung bÃ¬nh cá»™ng theo thá»i gian
        mfccs_processed = np.mean(mfccs.T, axis=0)
        return mfccs_processed
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi Ä‘á»c file {file_path}: {e}")
        return None

# --- BÆ¯á»šC 1: Xá»¬ LÃ Dá»® LIá»†U Äáº¦U VÃ€O ---
print("â–¶ï¸ Báº®T Äáº¦U Xá»¬ LÃ Dá»® LIá»†U...")

# Tá»± Ä‘á»™ng giáº£i nÃ©n náº¿u chÆ°a giáº£i nÃ©n
if os.path.exists(DATASET_ZIP):
    print(f"--> Äang giáº£i nÃ©n {DATASET_ZIP}...")
    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:
        zip_ref.extractall(".")
    print("--> Giáº£i nÃ©n xong!")
elif not os.path.exists(DATA_DIR):
    print(f"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file '{DATASET_ZIP}' cÅ©ng khÃ´ng tháº¥y thÆ° má»¥c '{DATA_DIR}'!")
    print("ğŸ‘‰ HÃ£y upload file zip lÃªn Colab trÆ°á»›c khi cháº¡y!")
    # Dá»«ng chÆ°Æ¡ng trÃ¬nh táº¡i Ä‘Ã¢y náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u
    raise SystemExit

features = []
labels = []

# Äá»‹nh nghÄ©a cáº¥u trÃºc dá»¯ liá»‡u cáº§n tÃ¬m
# Cáº¥u trÃºc: (TÃªn thÆ° má»¥c con, NhÃ£n gÃ¡n cho AI)
# NhÃ£n 1 = Chá»§ nhÃ , NhÃ£n 0 = NgÆ°á»i láº¡
structure = [
    (os.path.join(DATA_DIR, "chu_nha"), 1),
    (os.path.join(DATA_DIR, "nguoi_la"), 0)
]

# CÃ¡c Ä‘uÃ´i file cháº¥p nháº­n
extensions = ["*.wav", "*.mp3", "*.m4a"]

total_files = 0

for folder_path, label in structure:
    print(f"--> Äang quÃ©t thÆ° má»¥c: {folder_path}...")

    if not os.path.exists(folder_path):
        print(f"âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng tháº¥y thÆ° má»¥c {folder_path}. Bá» qua.")
        continue

    # QuÃ©t táº¥t cáº£ cÃ¡c Ä‘uÃ´i file
    files_found = []
    for ext in extensions:
        files_found.extend(glob.glob(os.path.join(folder_path, ext)))

    # Xá»­ lÃ½ tá»«ng file
    for file in files_found:
        data = extract_features(file)
        if data is not None:
            features.append(data)
            labels.append(label)
            total_files += 1

# Kiá»ƒm tra náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u thÃ¬ bÃ¡o lá»—i ngay
if len(features) == 0:
    print("âŒ Lá»–I NGHIÃŠM TRá»ŒNG: KhÃ´ng tÃ¬m tháº¥y báº¥t ká»³ file Ã¢m thanh nÃ o!")
    print("ğŸ‘‰ Kiá»ƒm tra láº¡i xem trong thÆ° má»¥c 'chu_nha' vÃ  'nguoi_la' cÃ³ file chÆ°a?")
    raise SystemExit

print(f"âœ… ÄÃƒ Xá»¬ LÃ XONG: Tá»•ng cá»™ng {len(features)} máº«u dá»¯ liá»‡u há»£p lá»‡.")

# --- BÆ¯á»šC 2: CHUáº¨N Bá»Š TRAIN ---
X = np.array(features)
y = np.array(labels)

# Chia dá»¯ liá»‡u: 80% há»c - 20% thi
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- BÆ¯á»šC 3: HUáº¤N LUYá»†N MODEL (MLP) ---
print("\nâ–¶ï¸ ÄANG HUáº¤N LUYá»†N AI (Training)...")

# Cáº¥u hÃ¬nh máº¡ng NÆ¡-ron:
# - hidden_layer_sizes=(128, 64): 2 lá»›p áº©n giÃºp AI thÃ´ng minh hÆ¡n
# - max_iter=500: Há»c tá»‘i Ä‘a 500 láº§n
model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, activation='relu', solver='adam', random_state=1)

model.fit(X_train, y_train)

# --- BÆ¯á»šC 4: ÄÃNH GIÃ Káº¾T QUáº¢ ---
print("\nâ–¶ï¸ Káº¾T QUáº¢ ÄÃNH GIÃ:")
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"ğŸ† Äá»˜ CHÃNH XÃC: {accuracy * 100:.2f}%")
print("-" * 30)
print(classification_report(y_test, y_pred, target_names=['NgÆ°á»i láº¡', 'Chá»§ nhÃ ']))

# --- BÆ¯á»šC 5: LÆ¯U MODEL ---
model_filename = 'model_giong_noi.pkl'
joblib.dump(model, model_filename)
print(f"âœ… ÄÃ£ lÆ°u model thÃ nh cÃ´ng vÃ o file: {model_filename}")
print("ğŸ‘‰ Báº¡n hÃ£y táº£i file nÃ y vá» mÃ¡y tÃ­nh Ä‘á»ƒ dÃ¹ng cho Project!")